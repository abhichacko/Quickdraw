{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "model = load_model('QuickDraw.h5')\n",
    "\n",
    "\n",
    "def main():\n",
    "    emojis = get_QD_emojis()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    Lower_green = np.array([110, 50, 50])\n",
    "    Upper_green = np.array([130, 255, 255])\n",
    "    pts = deque(maxlen=512)\n",
    "    blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    digit = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "    pred_class = 0\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        img = cv2.flip(img, 1)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        mask = cv2.inRange(hsv, Lower_green, Upper_green)\n",
    "        mask = cv2.erode(mask, kernel, iterations=2)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        # mask=cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "        res = cv2.bitwise_and(img, img, mask=mask)\n",
    "        cnts, heir = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "        center = None\n",
    "\n",
    "        if len(cnts) >= 1:\n",
    "            cnt = max(cnts, key=cv2.contourArea)\n",
    "            if cv2.contourArea(cnt) > 200:\n",
    "                ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "                cv2.circle(img, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "                cv2.circle(img, center, 5, (0, 0, 255), -1)\n",
    "                M = cv2.moments(cnt)\n",
    "                center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "                pts.appendleft(center)\n",
    "                for i in range(1, len(pts)):\n",
    "                    if pts[i - 1] is None or pts[i] is None:\n",
    "                        continue\n",
    "                    cv2.line(blackboard, pts[i - 1], pts[i], (255, 255, 255), 7)\n",
    "                    cv2.line(img, pts[i - 1], pts[i], (0, 0, 255), 2)\n",
    "        elif len(cnts) == 0:\n",
    "            if len(pts) != []:\n",
    "                blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
    "                blur1 = cv2.medianBlur(blackboard_gray, 15)\n",
    "                blur1 = cv2.GaussianBlur(blur1, (5, 5), 0)\n",
    "                thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "                blackboard_cnts, i = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "                print ('black',blackboard_cnts)\n",
    "                print('thresh',thresh1)\n",
    "                if len(blackboard_cnts) >= 1:   \n",
    "                    cnt = max(blackboard_cnts, key=cv2.contourArea)\n",
    "                    print(cv2.contourArea(cnt))\n",
    "                    if cv2.contourArea(cnt) > 2000:\n",
    "                        x, y, w, h = cv2.boundingRect(cnt)\n",
    "                        digit = blackboard_gray[y:y + h, x:x + w]\n",
    "                        pred_probab, pred_class = keras_predict(model, digit)\n",
    "                        print(pred_class, pred_probab)\n",
    "\n",
    "            pts = deque(maxlen=512)\n",
    "            blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "            img = overlay(img, emojis[pred_class], 400, 250, 100, 100)\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "def keras_predict(model, image):\n",
    "    processed = keras_process_image(image)\n",
    "    print(\"processed: \" + str(processed.shape))\n",
    "    pred_probab = model.predict(processed)[0]\n",
    "    pred_class = list(pred_probab).index(max(pred_probab))\n",
    "    return max(pred_probab), pred_class\n",
    "\n",
    "\n",
    "def keras_process_image(img):\n",
    "    image_x = 28\n",
    "    image_y = 28\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (-1, image_x, image_y, 1))\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_QD_emojis():\n",
    "    emojis_folder = 'qd_emo/'\n",
    "    emojis = []\n",
    "    for emoji in range(len(os.listdir(emojis_folder))):\n",
    "        print(emoji)\n",
    "        emojis.append(cv2.imread(emojis_folder + str(emoji) + '.png', -1))\n",
    "    return emojis\n",
    "\n",
    "\n",
    "def overlay(image, emoji, x, y, w, h):\n",
    "    emoji = cv2.resize(emoji, (w, h))\n",
    "    try:\n",
    "        image[y:y + h, x:x + w] = blend_transparent(image[y:y + h, x:x + w], emoji)\n",
    "    except:\n",
    "        pass\n",
    "    return image\n",
    "\n",
    "\n",
    "def blend_transparent(face_img, overlay_t_img):\n",
    "    # Split out the transparency mask from the colour info\n",
    "    overlay_img = overlay_t_img[:, :, :3]  # Grab the BRG planes\n",
    "    overlay_mask = overlay_t_img[:, :, 3:]  # And the alpha plane\n",
    "\n",
    "    # Again calculate the inverse mask\n",
    "    background_mask = 255 - overlay_mask\n",
    "\n",
    "    # Turn the masks into three channel, so we can use them as weights\n",
    "    overlay_mask = cv2.cvtColor(overlay_mask, cv2.COLOR_GRAY2BGR)\n",
    "    background_mask = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Create a masked out face image, and masked out overlay\n",
    "    # We convert the images to floating point in range 0.0 - 1.0\n",
    "    face_part = (face_img * (1 / 255.0)) * (background_mask * (1 / 255.0))\n",
    "    overlay_part = (overlay_img * (1 / 255.0)) * (overlay_mask * (1 / 255.0))\n",
    "\n",
    "    # And finally just add them together, and rescale it back to an 8bit integer image\n",
    "    return np.uint8(cv2.addWeighted(face_part, 255.0, overlay_part, 255.0, 0.0))\n",
    "\n",
    "\n",
    "keras_predict(model, np.zeros((50, 50, 1), dtype=np.uint8))\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drawing  using pen\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Define the upper and lower boundaries for a color to be considered \"Blue\"\n",
    "blueLower = np.array([100, 60, 60])\n",
    "blueUpper = np.array([140, 255, 255])\n",
    "\n",
    "# Define a 5x5 kernel for erosion and dilation\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Setup deques to store separate colors in separate arrays\n",
    "points = deque(maxlen=512)\n",
    "\n",
    "# Setup the Paint interface\n",
    "paintWindow = np.zeros((471,656,3)) + 255 #paint window\n",
    "cv2.namedWindow('Paint', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Load the video\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Keep looping\n",
    "while True:\n",
    "    # Grab the current paintWindow\n",
    "    key = cv2.waitKey(1)\n",
    "    (grabbed, frame) = camera.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Check to see if we have reached the end of the video\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # Determine which pixels fall within the blue boundaries and then blur the binary image\n",
    "    blueMask = cv2.inRange(hsv, blueLower, blueUpper)\n",
    "    blueMask = cv2.erode(blueMask, kernel, iterations=2)\n",
    "    blueMask = cv2.morphologyEx(blueMask, cv2.MORPH_OPEN, kernel)\n",
    "    blueMask = cv2.dilate(blueMask, kernel, iterations=1)\n",
    "\n",
    "    # Find contours in the image\n",
    "    cnts, x  = cv2.findContours(blueMask.copy(), cv2.RETR_EXTERNAL,\n",
    "    \tcv2.CHAIN_APPROX_SIMPLE)\n",
    "    center = None\n",
    "\n",
    "    # Check to see if any contours were found\n",
    "    if len(cnts) > 0:\n",
    "    \t# Sort the contours and find the largest one -- we\n",
    "    \t# will assume this contour correspondes to the area of the bottle cap\n",
    "        cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "        # Get the radius of the enclosing circle around the found contour\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "        # Draw the circle around the contour\n",
    "        cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "        # Get the moments to calculate the center of the contour (in this case Circle)\n",
    "        M = cv2.moments(cnt)\n",
    "        \n",
    "        #finding the center of the circle\n",
    "        center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "    points.appendleft(center)\n",
    "    # Append the next deque when no contours are detected (i.e., bottle cap reversed,blue not detected\n",
    "    for i in range(1,len(points)):\n",
    "        if points[i-1] is None or points[i] is None:\n",
    "            continue\n",
    "        cv2.line(frame, points[i - 1], points[i], (255, 0, 0), 2)\n",
    "        cv2.line(paintWindow, points[i - 1], points[i], (0, 0, 0), 3)\n",
    "                \n",
    "\n",
    "    # Show the frame and the paintWindow image\n",
    "    cv2.imshow(\"Tracking_frame\", frame)\n",
    "    cv2.imshow(\"PaintWindow\", paintWindow)\n",
    "    \n",
    "    if key & 0xFF == ord('r'):\n",
    "        points = deque(maxlen=512)\n",
    "        paintWindow[:,:,:] = 255\n",
    "    if key & 0xFF == ord('c'):\n",
    "            plt.imshow(paintWindow)\n",
    "            plt.show()\n",
    "\t# If the 'q' key is pressed, stop the loop\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# Cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
