{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "one\n",
      "two\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "# abhi\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "x = []\n",
    "x_load = []\n",
    "y = []\n",
    "y_load = []\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    count = 0\n",
    "    for file in tqdm(os.listdir(\"/home/abhi/mainproject/quickdraw/data\")):\n",
    "        file = \"/home/abhi/mainproject/quickdraw/data//\" + file\n",
    "        x = np.load(file)\n",
    "        x = x.astype('float32') / 255.\n",
    "        x = x[0:10000, :]\n",
    "        x_load.append(x)\n",
    "        y = [count for _ in range(10000)]\n",
    "        count += 1\n",
    "        y = np.array(y).astype('float32')\n",
    "        y = y.reshape(y.shape[0], 1)\n",
    "        y_load.append(y)\n",
    "\n",
    "    return x_load, y_load\n",
    "\n",
    "\n",
    "features, labels = load_data()\n",
    "\n",
    "features = np.array(features).astype('float32')\n",
    "labels = np.array(labels).astype('float32')\n",
    "\n",
    "# shape[0] number numpy files\n",
    "# shape[1] 10000\n",
    "features=features.reshape(features.shape[0]*features.shape[1],features.shape[2])\n",
    "# number of files * 10000 *784\n",
    "# print(features.shape)\n",
    "\n",
    "labels=labels.reshape(labels.shape[0]*labels.shape[1],labels.shape[2])\n",
    "# c=0\n",
    "# d=0\n",
    "# f=0\n",
    "# for i in labels:\n",
    "#     if (i ==2) and (c==0): \n",
    "#         print (\"two\")\n",
    "#         c=1\n",
    "\n",
    "#     if i==1 and d==0:\n",
    "#         print(\"one\")\n",
    "#         d=1\n",
    "#     if i==0 and f==0:\n",
    "#         print(\"zero\")\n",
    "#         f=1\n",
    "\n",
    "with open(\"features\", \"wb\") as f:\n",
    "    pickle.dump(features, f, protocol=2)\n",
    "with open(\"labels\", \"wb\") as f:\n",
    "    pickle.dump(labels, f, protocol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data loading manupulation\n",
    "# image from dataset printing\n",
    "# abhi\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os \n",
    "files = \"/home/abhi/mainproject/quickdraw/data/full_numpy_bitmap_envelope.npy\"\n",
    "x = np.load(files)\n",
    "print(x[0].shape)\n",
    "img=np.array(x[30000])\n",
    "img=np.reshape(img,(28,28))\n",
    "print(img.shape)\n",
    "# print(img)\n",
    "plt.imshow(img,cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (3000, 784)\n",
      "shape1 (3000, 28, 28, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 642,947\n",
      "Trainable params: 642,947\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 27000 samples, validate on 3000 samples\n",
      "Epoch 1/3\n",
      "27000/27000 [==============================] - 26s 966us/step - loss: 0.1622 - acc: 0.9396 - val_loss: 0.0708 - val_acc: 0.9753\n",
      "Epoch 2/3\n",
      "27000/27000 [==============================] - 25s 936us/step - loss: 0.0697 - acc: 0.9763 - val_loss: 0.0616 - val_acc: 0.9803\n",
      "Epoch 3/3\n",
      "27000/27000 [==============================] - 25s 943us/step - loss: 0.0545 - acc: 0.9805 - val_loss: 0.0688 - val_acc: 0.9763\n"
     ]
    }
   ],
   "source": [
    "# modelcreation\n",
    "# abhi\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Dense,Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "from keras.utils import np_utils, print_summary\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "def keras_model(image_x, image_y):\n",
    "    num_of_classes = 3\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(image_x,image_y,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    filepath = \"QuickDraw.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    return model, callbacks_list\n",
    "\n",
    "\n",
    "def loadFromPickle():\n",
    "    with open(\"features\", \"rb\") as f:\n",
    "        features = np.array(pickle.load(f))\n",
    "    with open(\"labels\", \"rb\") as f:\n",
    "        labels = np.array(pickle.load(f))\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "\n",
    "def prepress_labels(labels):\n",
    "    labels = np_utils.to_categorical(labels)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def main():\n",
    "    features, labels = loadFromPickle()\n",
    "    features, labels = shuffle(features, labels)\n",
    "    labels=prepress_labels(labels)\n",
    "#     print (\"labels prepress\",labels[1])\n",
    "    train_x, test_x, train_y, test_y = train_test_split(features, labels, random_state=0,                                                     test_size=0.1)\n",
    "    print(\"shape\",test_x.shape)\n",
    "    train_x = train_x.reshape(train_x.shape[0], 28, 28, 1)\n",
    "    test_x = test_x.reshape(test_x.shape[0], 28, 28, 1)\n",
    "    print(\"shape1\",test_x.shape)\n",
    "#     print(\"train_x[1]\",train_x[0])\n",
    "    model, callbacks_list = keras_model(28,28)\n",
    "    print_summary(model)\n",
    "    model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=3, batch_size=64,\n",
    "              callbacks=[TensorBoard(log_dir=\"QuickDraw\")])\n",
    "    model.save('QuickDraw.h5')\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before processs (600, 600)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new image (1, 28, 28, 1)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [1. 0. 0.]\n",
      "class 0\n",
      "the doodle is MOON\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def keras_process_image(img):\n",
    "    image_x = 28\n",
    "    image_y = 28\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (-1, image_x, image_y, 1))\n",
    "    return img\n",
    "\n",
    "test1=cv2.imread(\"test/moon.jpg\",0)\n",
    "\n",
    "model=load_model(\"QuickDraw.h5\")\n",
    "# test1=cv2.bitwise_not(test1)\n",
    "print(\"before processs\",test1.shape)\n",
    "# test=np.reshape(new_img,(28,28))\n",
    "\n",
    "# print(test.shape)\n",
    "\n",
    "\n",
    "plt.imshow(test1,cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "# blackboard_gray = cv2.cvtColor(test1, cv2.COLOR_BGR2GRAY)\n",
    "# # blackboard_gray=cv2.bitwise_not(blackboard_gray)\n",
    "# blur1 = cv2.medianBlur(blackboard_gray, 15)\n",
    "# blur1 = cv2.GaussianBlur(blur1, (5, 5), 0)\n",
    "# thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "# blackboard_cnts, i = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "# #                 print ('black',blackboard_cnts)\n",
    "# #                 print('thresh',thresh1)\n",
    "# plt.imshow(blackboard_gray,cmap=\"gray\")\n",
    "# plt.show()\n",
    "\n",
    "# if len(blackboard_cnts) >= 1:   \n",
    "#     cnt = max(blackboard_cnts, key=cv2.contourArea)\n",
    "#     print(cv2.contourArea(cnt))\n",
    "#     if cv2.contourArea(cnt) > 2000:\n",
    "#         x, y, w, h = cv2.boundingRect(cnt)\n",
    "#         digit = blackboard_gray[y:y + h, x:x + w]\n",
    "#         digit=cv2.bitwise_not(digit)\n",
    "#         processed = keras_process_image(digit)\n",
    "#         print(\"new image\",processed.shape)\n",
    "    \n",
    "#         print(\"processed: \" + str(processed.shape))\n",
    "#         pred_probab = model.predict(processed)[0]\n",
    "#         print(\"prob\",pred_probab)\n",
    "#         pred_class = list(pred_probab).index(max(pred_probab))\n",
    "#         print(\"class\",pred_class)\n",
    "#         if pred_class ==0 :\n",
    "#             print(\"the doodle is MOON\")\n",
    "#         elif pred_class ==1:\n",
    "#             print(\"the doodle is MOUNTAIN\")\n",
    "#         elif pred_class==2:\n",
    "#             print(\"the doodle is ENVELOPE\")\n",
    "#     else:\n",
    "#         print(\"no\")\n",
    "# else:\n",
    "#     print (\"no contour\")\n",
    "    \n",
    "    \n",
    "    \n",
    "digit=cv2.bitwise_not(test1)\n",
    "processed = keras_process_image(digit)\n",
    "print(\"new image\",processed.shape)\n",
    "\n",
    "print(\"processed: \" + str(processed.shape))\n",
    "pred_probab = model.predict(processed)[0]\n",
    "print(\"prob\",pred_probab)\n",
    "pred_class = list(pred_probab).index(max(pred_probab))\n",
    "print(\"class\",pred_class)\n",
    "if pred_class ==0 :\n",
    "    print(\"the doodle is MOON\")\n",
    "elif pred_class ==1:\n",
    "    print(\"the doodle is MOUNTAIN\")\n",
    "elif pred_class==2:\n",
    "    print(\"the doodle is ENVELOPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drawing  using pen\n",
    "# abhi\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Define the upper and lower boundaries for a color to be considered \"Blue\"\n",
    "blueLower = np.array([100, 60, 60])\n",
    "blueUpper = np.array([140, 255, 255])\n",
    "\n",
    "# Define a 5x5 kernel for erosion and dilation\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Setup deques to store separate colors in separate arrays\n",
    "points = deque(maxlen=512)\n",
    "\n",
    "# Setup the Paint interface\n",
    "paintWindow = np.zeros((400,600,3)) + 255 #paint window\n",
    "\n",
    "# cv2.imshow(i,paintWindow)\n",
    "\n",
    "\n",
    "\n",
    "x=0\n",
    "# Load the video\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Keep looping\n",
    "while True:\n",
    "    # Grab the current paintWindow\n",
    "    key = cv2.waitKey(1)\n",
    "    (grabbed, frame) = camera.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Check to see if we have reached the end of the video\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # Determine which pixels fall within the blue boundaries and then blur the binary image\n",
    "    blueMask = cv2.inRange(hsv, blueLower, blueUpper)\n",
    "    blueMask = cv2.erode(blueMask, kernel, iterations=2)\n",
    "    blueMask = cv2.morphologyEx(blueMask, cv2.MORPH_OPEN, kernel)\n",
    "    blueMask = cv2.dilate(blueMask, kernel, iterations=1)\n",
    "\n",
    "    # Find contours in the image\n",
    "    cnts, x  = cv2.findContours(blueMask.copy(), cv2.RETR_EXTERNAL,\n",
    "    \tcv2.CHAIN_APPROX_SIMPLE)\n",
    "    center = None\n",
    "\n",
    "    # Check to see if any contours were found\n",
    "    if len(cnts) > 0:\n",
    "    \t# Sort the contours and find the largest one -- we\n",
    "    \t# will assume this contour correspondes to the area of the bottle cap\n",
    "        cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "        # Get the radius of the enclosing circle around the found contour\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "        # Draw the circle around the contour\n",
    "        cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "        # Get the moments to calculate the center of the contour (in this case Circle)\n",
    "        M = cv2.moments(cnt)\n",
    "        \n",
    "        #finding the center of the circle\n",
    "        center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "    points.appendleft(center)\n",
    "    # Append the next deque when no contours are detected (i.e., bottle cap reversed,blue not detected\n",
    "    for i in range(1,len(points)):\n",
    "        if points[i-1] is None or points[i] is None:\n",
    "            continue\n",
    "        cv2.line(frame, points[i - 1], points[i], (255, 0, 0), 2)\n",
    "        cv2.line(paintWindow, points[i - 1], points[i], (0, 0, 0), 10)\n",
    "                \n",
    "\n",
    "    # Show the frame and the paintWindow image\n",
    "    cv2.imshow(\"Tracking_frame\", frame)\n",
    "    cv2.imshow(\"PaintWindow\", paintWindow)\n",
    "    \n",
    "    if key & 0xFF == ord('r'):\n",
    "        points = deque(maxlen=512)\n",
    "        paintWindow[:,:,:] = 255\n",
    "    if key & 0xFF == ord('c'):\n",
    "            plt.imshow(paintWindow)\n",
    "            plt.show() \n",
    "            cv2.imwrite(str(x)+\".jpg\",paintWindow)\n",
    "\t# If the 'q' key is pressed, stop the loop\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# Cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: (1, 28, 28, 1)\n",
      "prob [0.7908267  0.10053673 0.10863657]\n",
      "0\n",
      "emoji 0\n",
      "emoji 1\n",
      "emoji 2\n",
      "emoji 3\n",
      "emoji 4\n",
      "emoji 5\n",
      "emoji 6\n",
      "emoji 7\n",
      "emoji 8\n",
      "emoji 9\n",
      "emoji 10\n",
      "emoji 11\n",
      "emoji 12\n",
      "emoji 13\n",
      "emoji 14\n",
      "emoji 15\n",
      "12.0\n",
      "845.0\n",
      "69808.0\n",
      "digit (262, 356)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [0. 0. 1.]\n",
      "2\n",
      "predications\n",
      "class 2 prob 1.0\n",
      "378.5\n",
      "62335.5\n",
      "digit (254, 299)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [0. 0. 1.]\n",
      "2\n",
      "predications\n",
      "class 2 prob 1.0\n",
      "11116.0\n",
      "digit (308, 517)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [0. 1. 0.]\n",
      "1\n",
      "predications\n",
      "class 1 prob 1.0\n",
      "4767.5\n",
      "digit (423, 277)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [1. 0. 0.]\n",
      "0\n",
      "predications\n",
      "class 0 prob 1.0\n",
      "116411.5\n",
      "digit (368, 408)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [1. 0. 0.]\n",
      "0\n",
      "predications\n",
      "class 0 prob 1.0\n",
      "34510.5\n",
      "digit (280, 325)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [0. 0. 1.]\n",
      "2\n",
      "predications\n",
      "class 2 prob 1.0\n",
      "707.0\n",
      "39953.5\n",
      "digit (296, 371)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [1. 0. 0.]\n",
      "0\n",
      "predications\n",
      "class 0 prob 1.0\n",
      "905.0\n",
      "169.0\n",
      "5155.0\n",
      "digit (294, 342)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [1. 0. 0.]\n",
      "0\n",
      "predications\n",
      "class 0 prob 1.0\n",
      "6965.5\n",
      "digit (327, 349)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [1. 0. 0.]\n",
      "0\n",
      "predications\n",
      "class 0 prob 1.0\n",
      "6726.0\n",
      "digit (246, 364)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [1. 0. 0.]\n",
      "0\n",
      "predications\n",
      "class 0 prob 1.0\n",
      "1908.5\n",
      "1399.5\n",
      "17776.5\n",
      "digit (240, 224)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [0. 1. 0.]\n",
      "1\n",
      "predications\n",
      "class 1 prob 1.0\n",
      "8131.0\n",
      "digit (346, 411)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [0. 1. 0.]\n",
      "1\n",
      "predications\n",
      "class 1 prob 1.0\n",
      "1166.0\n",
      "2870.5\n",
      "digit (186, 168)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [0. 1. 0.]\n",
      "1\n",
      "predications\n",
      "class 1 prob 1.0\n",
      "4027.0\n",
      "digit (320, 236)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [0. 0. 1.]\n",
      "2\n",
      "predications\n",
      "class 2 prob 1.0\n",
      "20339.5\n",
      "digit (444, 423)\n",
      "processed: (1, 28, 28, 1)\n",
      "prob [0. 1. 0.]\n",
      "1\n",
      "predications\n",
      "class 1 prob 1.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "model = load_model('QuickDraw.h5')\n",
    "\n",
    "\n",
    "def main():\n",
    "    emojis = get_QD_emojis()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    Lower_green = np.array([100, 60, 60])\n",
    "    Upper_green = np.array([140, 255, 255])\n",
    "    pts = deque(maxlen=512)\n",
    "    blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    digit = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "    pred_class = 0\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        img = cv2.flip(img, 1)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        mask = cv2.inRange(hsv, Lower_green, Upper_green)\n",
    "        mask = cv2.erode(mask, kernel, iterations=2)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        # mask=cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "        res = cv2.bitwise_and(img, img, mask=mask)\n",
    "        cnts, heir = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "        center = None\n",
    "\n",
    "        if len(cnts) >= 1:\n",
    "            cnt = max(cnts, key=cv2.contourArea)\n",
    "            if cv2.contourArea(cnt) > 200:\n",
    "                ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "                cv2.circle(img, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "                cv2.circle(img, center, 5, (0, 0, 255), -1)\n",
    "                M = cv2.moments(cnt)\n",
    "                center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "                pts.appendleft(center)\n",
    "                for i in range(1, len(pts)):\n",
    "                    if pts[i - 1] is None or pts[i] is None:\n",
    "                        continue\n",
    "                    cv2.line(blackboard, pts[i - 1], pts[i], (255, 255, 255), 7)\n",
    "                    cv2.line(img, pts[i - 1], pts[i], (0, 0, 255), 2)\n",
    "        elif len(cnts) == 0:\n",
    "            if len(pts) != []:\n",
    "                blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
    "                blur1 = cv2.medianBlur(blackboard_gray, 15)\n",
    "                blur1 = cv2.GaussianBlur(blur1, (5, 5), 0)\n",
    "                thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "                blackboard_cnts, i = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "#                 print ('black',blackboard_cnts)\n",
    "#                 print('thresh',thresh1)\n",
    "                if len(blackboard_cnts) >= 1:   \n",
    "                    cnt = max(blackboard_cnts, key=cv2.contourArea)\n",
    "                    print(cv2.contourArea(cnt))\n",
    "                    if cv2.contourArea(cnt) > 2000:\n",
    "                        x, y, w, h = cv2.boundingRect(cnt)\n",
    "                        digit = blackboard_gray[y:y + h, x:x + w]\n",
    "                        print(\"digit\",digit.shape)\n",
    "                        pred_probab, pred_class = keras_predict(model, digit)\n",
    "                        print(\"predications\")\n",
    "                        print(\"class\",pred_class,\"prob\", pred_probab)\n",
    "\n",
    "            pts = deque(maxlen=512)\n",
    "            blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "            img = overlay(img, emojis[pred_class], 400, 250, 100, 100)\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "def keras_predict(model, image):\n",
    "    processed = keras_process_image(image)\n",
    "    print(\"processed: \" + str(processed.shape))\n",
    "    pred_probab = model.predict(processed)[0]\n",
    "    print(\"prob\",pred_probab)\n",
    "    pred_class = list(pred_probab).index(max(pred_probab))\n",
    "    print(pred_class)\n",
    "    return max(pred_probab), pred_class\n",
    "\n",
    "\n",
    "def keras_process_image(img):\n",
    "    image_x = 28\n",
    "    image_y = 28\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (-1, image_x, image_y, 1))\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_QD_emojis():\n",
    "    emojis_folder = 'qd_emo/'\n",
    "    emojis = []\n",
    "    for emoji in range(len(os.listdir(emojis_folder))):\n",
    "        print(\"emoji\",emoji)\n",
    "        emojis.append(cv2.imread(emojis_folder + str(emoji) + '.png', -1))\n",
    "    return emojis\n",
    "\n",
    "\n",
    "def overlay(image, emoji, x, y, w, h):\n",
    "    emoji = cv2.resize(emoji, (w, h))\n",
    "    try:\n",
    "        image[y:y + h, x:x + w] = blend_transparent(image[y:y + h, x:x + w], emoji)\n",
    "    except:\n",
    "        pass\n",
    "    return image\n",
    "\n",
    "\n",
    "def blend_transparent(face_img, overlay_t_img):\n",
    "    # Split out the transparency mask from the colour info\n",
    "    overlay_img = overlay_t_img[:, :, :3]  # Grab the BRG planes\n",
    "    overlay_mask = overlay_t_img[:, :, 3:]  # And the alpha plane\n",
    "\n",
    "    # Again calculate the inverse mask\n",
    "    background_mask = 255 - overlay_mask\n",
    "\n",
    "    # Turn the masks into three channel, so we can use them as weights\n",
    "    overlay_mask = cv2.cvtColor(overlay_mask, cv2.COLOR_GRAY2BGR)\n",
    "    background_mask = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Create a masked out face image, and masked out overlay\n",
    "    # We convert the images to floating point in range 0.0 - 1.0\n",
    "    face_part = (face_img * (1 / 255.0)) * (background_mask * (1 / 255.0))\n",
    "    overlay_part = (overlay_img * (1 / 255.0)) * (overlay_mask * (1 / 255.0))\n",
    "\n",
    "    # And finally just add them together, and rescale it back to an 8bit integer image\n",
    "    return np.uint8(cv2.addWeighted(face_part, 255.0, overlay_part, 255.0, 0.0))\n",
    "\n",
    "\n",
    "keras_predict(model, np.zeros((50, 50, 1), dtype=np.uint8))\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x=np.zeros((2,3,4))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1,2,3,4,5,6]\n",
    "x = [0:2, :] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def main():\n",
    "    area=(100,100,300,300)\n",
    "    paintWindow = np.zeros((471,656,3)) + 255 #paint window\n",
    "\n",
    "    # cv2.namedWindow('Paint', cv2.WINDOW_AUTOSIZE)\n",
    "    img=cv2.imread('images/home1.jpg',cv2.COLOR_BGR2HSV)\n",
    "    print(len(img.shape))\n",
    "    print(len(paintWindow.shape))\n",
    "#     i=np.reshape(i,(400,400,-1))\n",
    "  \n",
    "    print(paintWindow.shape)\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show()\n",
    "    camera = cv2.VideoCapture(0)\n",
    "\n",
    "    \n",
    "    # Keep looping\n",
    "    while True:\n",
    "        # Grab the current paintWindow\n",
    "        key = cv2.waitKey(1)\n",
    "        (grabbed, frame) = camera.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        image = Image.fromarray(paintWindow.astype('uint8'), 'RGB')\n",
    "        image.paste(img,area)\n",
    "        cv2.imshow(image)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    # Cleanup the camera and close any open windows\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
