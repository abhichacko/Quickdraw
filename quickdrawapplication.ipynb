{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# abhi\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "x = []\n",
    "x_load = []\n",
    "y = []\n",
    "y_load = []\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    count = 0\n",
    "    for file in tqdm(os.listdir(\"/home/abhi/mainproject/quickdraw/data\")):\n",
    "        file = \"/home/abhi/mainproject/quickdraw/data//\" + file\n",
    "        x = np.load(file)\n",
    "        x = x.astype('float32') / 255.\n",
    "        x = x[0:10000, :]\n",
    "        x_load.append(x)\n",
    "        y = [count for _ in range(10000)]\n",
    "        count += 1\n",
    "        y = np.array(y).astype('float32')\n",
    "        y = y.reshape(y.shape[0], 1)\n",
    "        y_load.append(y)\n",
    "\n",
    "    return x_load, y_load\n",
    "\n",
    "\n",
    "features, labels = load_data()\n",
    "\n",
    "features = np.array(features).astype('float32')\n",
    "labels = np.array(labels).astype('float32')\n",
    "\n",
    "# shape[0] number numpy files\n",
    "# shape[1] 10000\n",
    "features=features.reshape(features.shape[0]*features.shape[1],features.shape[2])\n",
    "# number of files * 10000 *784\n",
    "# print(features.shape)\n",
    "\n",
    "labels=labels.reshape(labels.shape[0]*labels.shape[1],labels.shape[2])\n",
    "# c=0\n",
    "# d=0\n",
    "# f=0\n",
    "# for i in labels:\n",
    "#     if (i ==2) and (c==0): \n",
    "#         print (\"two\")\n",
    "#         c=1\n",
    "\n",
    "#     if i==1 and d==0:\n",
    "#         print(\"one\")\n",
    "#         d=1\n",
    "#     if i==0 and f==0:\n",
    "#         print(\"zero\")\n",
    "#         f=1\n",
    "\n",
    "with open(\"features\", \"wb\") as f:\n",
    "    pickle.dump(features, f, protocol=2)\n",
    "with open(\"labels\", \"wb\") as f:\n",
    "    pickle.dump(labels, f, protocol=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading manupulation\n",
    "# image from dataset printing\n",
    "# abhi\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os \n",
    "files = \"/home/abhi/mainproject/quickdraw/data/full_numpy_bitmap_envelope.npy\"\n",
    "x = np.load(files)\n",
    "print(x[0].shape)\n",
    "img=np.array(x[30000])\n",
    "img=np.reshape(img,(28,28))\n",
    "print(img.shape)\n",
    "# print(img)\n",
    "plt.imshow(img,cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelcreation\n",
    "# abhi\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Dense,Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "from keras.utils import np_utils, print_summary\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "def keras_model(image_x, image_y):\n",
    "    num_of_classes = 3\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(image_x,image_y,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    filepath = \"QuickDraw.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    return model, callbacks_list\n",
    "\n",
    "\n",
    "def loadFromPickle():\n",
    "    with open(\"features\", \"rb\") as f:\n",
    "        features = np.array(pickle.load(f))\n",
    "    with open(\"labels\", \"rb\") as f:\n",
    "        labels = np.array(pickle.load(f))\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "\n",
    "def prepress_labels(labels):\n",
    "    labels = np_utils.to_categorical(labels)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def main():\n",
    "    features, labels = loadFromPickle()\n",
    "    features, labels = shuffle(features, labels)\n",
    "    labels=prepress_labels(labels)\n",
    "#     print (\"labels prepress\",labels[1])\n",
    "    train_x, test_x, train_y, test_y = train_test_split(features, labels, random_state=0,                                                     test_size=0.1)\n",
    "    print(\"shape\",test_x.shape)\n",
    "    train_x = train_x.reshape(train_x.shape[0], 28, 28, 1)\n",
    "    test_x = test_x.reshape(test_x.shape[0], 28, 28, 1)\n",
    "    print(\"shape1\",test_x.shape)\n",
    "#     print(\"train_x[1]\",train_x[0])\n",
    "    model, callbacks_list = keras_model(28,28)\n",
    "    print_summary(model)\n",
    "    model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=3, batch_size=64,\n",
    "              callbacks=[TensorBoard(log_dir=\"QuickDraw\")])\n",
    "    model.save('QuickDraw.h5')\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def keras_process_image(img):\n",
    "    image_x = 28\n",
    "    image_y = 28\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (-1, image_x, image_y, 1))\n",
    "    return img\n",
    "\n",
    "test1=cv2.imread(\"test/c\",0)\n",
    "\n",
    "model=load_model(\"QuickDraw.h5\")\n",
    "\n",
    "print(\"before processs\",test1.shape)\n",
    "plt.imshow(test1,cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "digit=cv2.bitwise_not(test1)\n",
    "processed = keras_process_image(digit)\n",
    "print(\"new image\",processed.shape)\n",
    "\n",
    "print(\"processed: \" + str(processed.shape))\n",
    "pred_probab = model.predict(processed)[0]\n",
    "print(\"prob\",pred_probab)\n",
    "pred_class = list(pred_probab).index(max(pred_probab))\n",
    "print(\"class\",pred_class)\n",
    "if pred_class ==0 :\n",
    "    print(\"the doodle is MOON\")\n",
    "elif pred_class ==1:\n",
    "    print(\"the doodle is MOUNTAIN\")\n",
    "elif pred_class==2:\n",
    "    print(\"the doodle is ENVELOPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('new image', (1, 28, 28, 1))\n",
      "processed: (1, 28, 28, 1)\n",
      "('prob', array([1., 0., 0.], dtype=float32))\n",
      "('class', 0)\n",
      "the doodle is MOON\n"
     ]
    }
   ],
   "source": [
    "# drawing  using pen\n",
    "# abhi\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import os\n",
    "\n",
    "model=load_model(\"QuickDraw.h5\")\n",
    "\n",
    "def keras_process_image(img,image_x = 28,image_y = 28):\n",
    "\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (-1, image_x, image_y, 1))\n",
    "    return img\n",
    "\n",
    "# Define the upper and lower boundaries for a color to be considered \"Blue\"\n",
    "blueLower = np.array([100, 60, 60])\n",
    "blueUpper = np.array([140, 255, 255])\n",
    "\n",
    "# Define a 5x5 kernel for erosion and dilation\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Setup deques to store separate colors in separate arrays\n",
    "points = deque(maxlen=512)\n",
    "\n",
    "# Setup the Paint interface\n",
    "paintWindow = np.zeros((480,670,3)) + 255 #paint window\n",
    "\n",
    "# cv2.imshow(i,paintWindow)\n",
    "\n",
    "\n",
    "\n",
    "x=0\n",
    "# Load the video\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Keep looping\n",
    "while True:\n",
    "    # Grab the current paintWindow\n",
    "    key = cv2.waitKey(1)\n",
    "    (grabbed, frame) = camera.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Check to see if we have reached the end of the video\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # Determine which pixels fall within the blue boundaries and then blur the binary image\n",
    "    blueMask = cv2.inRange(hsv, blueLower, blueUpper)\n",
    "    blueMask = cv2.erode(blueMask, kernel, iterations=2)\n",
    "    blueMask = cv2.morphologyEx(blueMask, cv2.MORPH_OPEN, kernel)\n",
    "    blueMask = cv2.dilate(blueMask, kernel, iterations=1)\n",
    "\n",
    "    # Find contours in the image\n",
    "    cnts, x  = cv2.findContours(blueMask.copy(), cv2.RETR_EXTERNAL,\n",
    "    \tcv2.CHAIN_APPROX_SIMPLE)\n",
    "    center = None\n",
    "\n",
    "    # Check to see if any contours were found\n",
    "    if len(cnts) > 0:\n",
    "    \t# Sort the contours and find the largest one -- we\n",
    "    \t# will assume this contour correspondes to the area of the bottle cap\n",
    "        cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "        # Get the radius of the enclosing circle around the found contour\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "        # Draw the circle around the contour\n",
    "        cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "        # Get the moments to calculate the center of the contour (in this case Circle)\n",
    "        M = cv2.moments(cnt)\n",
    "        \n",
    "        #finding the center of the circle\n",
    "        center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "    points.appendleft(center)\n",
    "    # Append the next deque when no contours are detected (i.e., bottle cap reversed,blue not detected\n",
    "    for i in range(1,len(points)):\n",
    "        if points[i-1] is None or points[i] is None:\n",
    "            continue\n",
    "        cv2.line(frame, points[i - 1], points[i], (255, 0, 0), 2)\n",
    "        cv2.line(paintWindow, points[i - 1], points[i], (0, 0, 0), 10)\n",
    "                \n",
    "\n",
    "    # Show the frame and the paintWindow image\n",
    "    cv2.imshow(\"Tracking_frame\", frame)\n",
    "    cv2.imshow(\"PaintWindow\", paintWindow)\n",
    "    \n",
    "    if key & 0xFF == ord('r'):\n",
    "        points = deque(maxlen=512)\n",
    "        paintWindow[:,:,:] = 255\n",
    "    if key & 0xFF == ord('c'):\n",
    "#             plt.imshow(paintWindow)\n",
    "#             plt.show() \n",
    "            cv2.imwrite(str(x)+\".jpg\",paintWindow)\n",
    "    if key & 0xFF == ord('p'):\n",
    "#         plt.imshow(paintWindow)\n",
    "#         plt.show() \n",
    "        cv2.imwrite(str(x)+\".jpg\",paintWindow)\n",
    "        i=cv2.imread(str(x)+\".jpg\",0)\n",
    "#         i=cv2.cvtColor(i,cv2.COLOR_BGR2GRAY)\n",
    "        digit=cv2.bitwise_not(i)\n",
    "        plt.imshow(digit,cmap=\"gray\")\n",
    "        plt.show()\n",
    "        processed = keras_process_image(digit)\n",
    "        print(\"new image\",processed.shape)\n",
    "        \n",
    "        print(\"processed: \" + str(processed.shape))\n",
    "        pred_probab = model.predict(processed)[0]\n",
    "        print(\"prob\",pred_probab)\n",
    "        pred_class = list(pred_probab).index(max(pred_probab))\n",
    "        print(\"class\",pred_class)\n",
    "        if pred_class ==0 :\n",
    "            print(\"the doodle is MOON\")\n",
    "            cv2.putText(paintWindow, \"prediction : MOON\", (108, 33), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "        elif pred_class ==1:\n",
    "            print(\"the doodle is MOUNTAIN\")\n",
    "            cv2.putText(paintWindow, \"prediction : MOUNTAIN\", (108, 33), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "        elif pred_class==2:\n",
    "            print(\"the doodle is ENVELOPE\")\n",
    "            cv2.putText(paintWindow, \"prediction : ENVELOPE\", (108, 33), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "            img=cv2.imread(\"c1.jpg\")\n",
    "            cv2.imshow(\"PaintWindow\", img)\n",
    "        os.remove(str(x)+\".jpg\")\n",
    "\t# If the 'q' key is pressed, stop the loop\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "# Cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "model = load_model('QuickDraw.h5')\n",
    "\n",
    "\n",
    "def main():\n",
    "    emojis = get_QD_emojis()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    Lower_green = np.array([100, 60, 60])\n",
    "    Upper_green = np.array([140, 255, 255])\n",
    "    pts = deque(maxlen=512)\n",
    "    blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    digit = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "    pred_class = 0\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        img = cv2.flip(img, 1)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        mask = cv2.inRange(hsv, Lower_green, Upper_green)\n",
    "        mask = cv2.erode(mask, kernel, iterations=2)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        # mask=cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "        res = cv2.bitwise_and(img, img, mask=mask)\n",
    "        cnts, heir = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "        center = None\n",
    "\n",
    "        if len(cnts) >= 1:\n",
    "            cnt = max(cnts, key=cv2.contourArea)\n",
    "            if cv2.contourArea(cnt) > 200:\n",
    "                ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "                cv2.circle(img, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "                cv2.circle(img, center, 5, (0, 0, 255), -1)\n",
    "                M = cv2.moments(cnt)\n",
    "                center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "                pts.appendleft(center)\n",
    "                for i in range(1, len(pts)):\n",
    "                    if pts[i - 1] is None or pts[i] is None:\n",
    "                        continue\n",
    "                    cv2.line(blackboard, pts[i - 1], pts[i], (255, 255, 255), 7)\n",
    "                    cv2.line(img, pts[i - 1], pts[i], (0, 0, 255), 2)\n",
    "        elif len(cnts) == 0:\n",
    "            if len(pts) != []:\n",
    "                blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
    "                blur1 = cv2.medianBlur(blackboard_gray, 15)\n",
    "                blur1 = cv2.GaussianBlur(blur1, (5, 5), 0)\n",
    "                thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "                blackboard_cnts, i = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "#                 print ('black',blackboard_cnts)\n",
    "#                 print('thresh',thresh1)\n",
    "                if len(blackboard_cnts) >= 1:   \n",
    "                    cnt = max(blackboard_cnts, key=cv2.contourArea)\n",
    "                    print(cv2.contourArea(cnt))\n",
    "                    if cv2.contourArea(cnt) > 2000:\n",
    "                        x, y, w, h = cv2.boundingRect(cnt)\n",
    "                        digit = blackboard_gray[y:y + h, x:x + w]\n",
    "                        print(\"digit\",digit.shape)\n",
    "                        pred_probab, pred_class = keras_predict(model, digit)\n",
    "                        print(\"predications\")\n",
    "                        print(\"class\",pred_class,\"prob\", pred_probab)\n",
    "\n",
    "            pts = deque(maxlen=512)\n",
    "            blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "            img = overlay(img, emojis[pred_class], 400, 250, 100, 100)\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "def keras_predict(model, image):\n",
    "    processed = keras_process_image(image)\n",
    "    print(\"processed: \" + str(processed.shape))\n",
    "    pred_probab = model.predict(processed)[0]\n",
    "    print(\"prob\",pred_probab)\n",
    "    pred_class = list(pred_probab).index(max(pred_probab))\n",
    "    print(pred_class)\n",
    "    return max(pred_probab), pred_class\n",
    "\n",
    "\n",
    "def keras_process_image(img):\n",
    "    image_x = 28\n",
    "    image_y = 28\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (-1, image_x, image_y, 1))\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_QD_emojis():\n",
    "    emojis_folder = 'qd_emo/'\n",
    "    emojis = []\n",
    "    for emoji in range(len(os.listdir(emojis_folder))):\n",
    "        print(\"emoji\",emoji)\n",
    "        emojis.append(cv2.imread(emojis_folder + str(emoji) + '.png', -1))\n",
    "    return emojis\n",
    "\n",
    "\n",
    "def overlay(image, emoji, x, y, w, h):\n",
    "    emoji = cv2.resize(emoji, (w, h))\n",
    "    try:\n",
    "        image[y:y + h, x:x + w] = blend_transparent(image[y:y + h, x:x + w], emoji)\n",
    "    except:\n",
    "        pass\n",
    "    return image\n",
    "\n",
    "\n",
    "def blend_transparent(face_img, overlay_t_img):\n",
    "    # Split out the transparency mask from the colour info\n",
    "    overlay_img = overlay_t_img[:, :, :3]  # Grab the BRG planes\n",
    "    overlay_mask = overlay_t_img[:, :, 3:]  # And the alpha plane\n",
    "\n",
    "    # Again calculate the inverse mask\n",
    "    background_mask = 255 - overlay_mask\n",
    "\n",
    "    # Turn the masks into three channel, so we can use them as weights\n",
    "    overlay_mask = cv2.cvtColor(overlay_mask, cv2.COLOR_GRAY2BGR)\n",
    "    background_mask = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Create a masked out face image, and masked out overlay\n",
    "    # We convert the images to floating point in range 0.0 - 1.0\n",
    "    face_part = (face_img * (1 / 255.0)) * (background_mask * (1 / 255.0))\n",
    "    overlay_part = (overlay_img * (1 / 255.0)) * (overlay_mask * (1 / 255.0))\n",
    "\n",
    "    # And finally just add them together, and rescale it back to an 8bit integer image\n",
    "    return np.uint8(cv2.addWeighted(face_part, 255.0, overlay_part, 255.0, 0.0))\n",
    "\n",
    "\n",
    "keras_predict(model, np.zeros((50, 50, 1), dtype=np.uint8))\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x=np.zeros((2,3,4))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1,2,3,4,5,6]\n",
    "x = [0:2, :] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def main():\n",
    "    area=(100,100,300,300)\n",
    "    paintWindow = np.zeros((471,656,3)) + 255 #paint window\n",
    "\n",
    "    # cv2.namedWindow('Paint', cv2.WINDOW_AUTOSIZE)\n",
    "    img=cv2.imread('images/home1.jpg',cv2.COLOR_BGR2HSV)\n",
    "    print(len(img.shape))\n",
    "    print(len(paintWindow.shape))\n",
    "#     i=np.reshape(i,(400,400,-1))\n",
    "  \n",
    "    print(paintWindow.shape)\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show()\n",
    "    camera = cv2.VideoCapture(0)\n",
    "\n",
    "    \n",
    "    # Keep looping\n",
    "    while True:\n",
    "        # Grab the current paintWindow\n",
    "        key = cv2.waitKey(1)\n",
    "        (grabbed, frame) = camera.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        image = Image.fromarray(paintWindow.astype('uint8'), 'RGB')\n",
    "        image.paste(img,area)\n",
    "        cv2.imshow(image)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    # Cleanup the camera and close any open windows\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
